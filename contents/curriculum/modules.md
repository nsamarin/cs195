---
layout: default
title: Modules
parent: Curriculum
nav_order: 1
---


# Module 1. Professional Ethics, Values, and Case Studies

# Module 2. Privacy, Surveillance, and Free Speech

Summary of the module goes here.

## Learning Objectives
- Learning Objective I
- Learning Objective II
- Learning Objective III

## Resources

[Resources go here.]

## Activities

[Activities go here.]


## Submodules

### Submodule A. Overview

Summary of the submodule goes here.

### Readings
Yang, "Op-Ed by Andrew Yang: Make tech companies pay you for your data"

Menand, "Why Do We Care So Much About Privacy?"

MacMillan, Anderson, "Student tracking, secret scores: How college admissions offices rank prospects before they apply"

Gallagher, "I Used to Work for Google. I Am a Conscientious Objector."

BBC News, "Microsoft says error caused 'Tank Man' Bing censorship" 

### Discussion
What does “privacy” mean to you and when do you have a reasonable expectation of privacy?

Think about examples of surveillance that is enabled or assisted by computer technologies. What are the benefits and dangers of such surveillance? Please refer to specific examples of surveillance in your response.

Do you take any steps to protect your privacy online? Why or why not?

### Submodule B. Vulnerable Populations

Summary of the submodule goes here.

### Readings
Tom Simonite, “CryptoHarlem’s Founder Warns Against ‘Digital Stop and Frisk’”

Joseph Cox, “I Gave a Bounty Hunter $300. Then He Located Our Phone”

Allie Funk, “Apple’s AirTag offers convenience but poses serious threats — and it’s not alone”

Sara Morrison and Adam Clark Estes, “How protesters are turning the tables on police surveillance”

[Skim] William R. Marczak et al., “When Governments Hack Opponents: A Look at Actors and Technology”

[Skim] Sam Biddle, “Police Surveilled George Floyd Protests with the Help from Twitter-affiliated Startup Dataminr”

### Discussion

Recall the article describing the ways in which Apple’s AirTags can be abused. Which safeguards has Apple implemented to prevent such abuses? Do you believe those safeguards are sufficient to prevent the abuse of AirTags or not?

What are the implications of the increasing capabilities of the public to conduct surveillance (e.g. using their smartphones) on other actors, such as the law enforcement, and on each other?

The readings discuss the disproportionate impact of tech-enabled surveillance on marginalized communities. In your opinion, which groups or actors (if any) benefit (directly or indirectly) from the excessive surveillance of vulnerable groups?

### Submodule C. Human Factors

Summary of the submodule goes here.

### Readings

Alessandfro Acquisti, Laura Brandimarte, and George Loewenstein, “Privacy and human behavior in the age of information”

Ivano Bongiovanni, Karen Renaud, and Noura Aleisa, “The privacy paradox: we claim we care about our data, so why don’t our actions match?”

Arielle Pardes, “How Facebook and Other Sites Manipulate Your Privacy Choices”

Genia Kostka, “What do people in China think about ‘social credit’ monitoring?”

[Skim] Institute of Global Health Innovation (IGHI), “Covid-19: Perceptions of Contact Tracing Global Report”

[Skim] Laura Brandimarte and Alessandro Acquisti, “The Economics of Privacy” (Skip Chapter 4)

### Discussion

Consider the strategies that one might adopt to preserve their privacy: using a VPN, having long passwords, reading privacy policies, etc. Should it be our responsibility to take these actions to ensure our privacy is protected? If yes, then why? If not, then whose responsibility should it be?

Imagine that you are employed at ShadyTech, LLC and they ask you to design a product that would maximize their profits through careful UI design. What dark patterns you might employ to achieve this? For each pattern, describe the dark pattern and its intended impact on user behavior. 

Recall the reading describing the attitudes of people in China towards ‘social credit’ monitoring. If a similar scoring system were proposed in the US, how might the attitude of the American public be different and how might it be similar? In responding to this question, feel free to draw parallels with existing scoring systems used in the US. 


# Module 3. Software Risks and Algorithmic Decision-Making

# Module 4. Technology Law and Policy

